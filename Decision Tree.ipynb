{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree is built from scratch, however I use some helper functions from other libraries: pandas for reading the data into a dataframe, random for shuffling the data before splitting, scipy.stats for the entropy function, and sklearn.metrics for the F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import scipy.stats\n",
    "import sklearn.metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = pd.read_csv('HTRU_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I split the data into the pulsars (data_1) and not pulsars (data_0). I then shuffle these individually, and take the first 90% of the shuffled data_0 and data_1, and use this for training data. The remaining 10% is for testing data. I split them individually so I have an equal proportion of positive samples in the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(range(original_data.shape[0]))\n",
    "\n",
    "data_0 = original_data.Class == 0\n",
    "labels_0 = [i for i in data_0.index if data_0[i]]\n",
    "data_1 = original_data.Class == 1\n",
    "labels_1 = [i for i in data_1.index if data_1[i]]\n",
    "\n",
    "random.seed(503)\n",
    "random.shuffle(labels_0)\n",
    "random.shuffle(labels_1)\n",
    "\n",
    "split_point_0 = int(0.9*len(labels_0))\n",
    "split_point_1 = int(0.9*len(labels_1))\n",
    "\n",
    "train_labels = labels_0[:split_point_0] + labels_1[:split_point_1]\n",
    "test_labels = labels_0[split_point_0:] + labels_1[split_point_1:]\n",
    "\n",
    "random.shuffle(train_labels)\n",
    "random.shuffle(test_labels)\n",
    "\n",
    "train_data = original_data.loc[train_labels].copy(deep=True)\n",
    "test_data = original_data.loc[test_labels].copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class Node represents any node in the decision tree which has children\n",
    "\n",
    "PredictionNode represents a node with no children i.e. it is a leaf node\n",
    "\n",
    "DecisionTree represents a collection of nodes, beginning with the root node. This class keeps track of how many nodes are in the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionNode:\n",
    "    def __init__(self, column, threshold, info_gain):\n",
    "        self.column = column\n",
    "        self.threshold = threshold\n",
    "        self.info_gain = info_gain\n",
    "    def addLeftChild(self, child):\n",
    "        self.left_child = child\n",
    "    def addRightChild(self, child):\n",
    "        self.right_child = child\n",
    "    def print_node(self):\n",
    "        print(\"Column: \", self.column)\n",
    "        print(\"Threshold: \", self.threshold)\n",
    "        print(\"Info gain: \", self.info_gain)\n",
    "        \n",
    "class PredictionNode:\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "    def prediction(self):\n",
    "        return self.value\n",
    "    def print_node(self):\n",
    "        print(\"Prediction: \", self.prediction)\n",
    "        \n",
    "# class DecisionTree:\n",
    "#     def __init__(self, root_node):\n",
    "#         self.root_node = root_node\n",
    "#         self.count = 1\n",
    "#     def addNode(self):\n",
    "#         self.count += 1\n",
    "#     def countNodes(self):\n",
    "#         return count        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split_column() creates a temporary column 'temp' based on the value of the provided column. If the value in the provided column is above the threshold value, the 'temp' value is 1, otherwise 0. This function is used in information_gain(), to calculate the information gain obtained from a particular variable split with a particular threshold value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_column(column_name, threshold, data):\n",
    "    data['temp'] = 0\n",
    "    filt = data[column_name] > threshold\n",
    "    data.loc[filt,'temp'] = 1\n",
    "    \n",
    "def information_gain(entropy, data):\n",
    "#     if(data.shape[0] < 0.01*original_data.shape[0] or data['Class'].mode()[0] == data['Class'].shape[0]):\n",
    "    if(data['Class'].mode()[0] == data['Class'].shape[0]):\n",
    "        return 0\n",
    "    filt = data['temp'] == 0\n",
    "    counts_0 = data.loc[filt, 'Class'].value_counts()\n",
    "    entropy_0 = scipy.stats.entropy(counts_0)\n",
    "    size_0 = data[filt].shape[0]\n",
    "    filt = data['temp'] == 1\n",
    "    counts_1 = data.loc[filt, 'Class'].value_counts()\n",
    "    entropy_1 = scipy.stats.entropy(counts_1)\n",
    "    size_1 = data[filt].shape[0]\n",
    "    orig_size = data.shape[0]\n",
    "\n",
    "    return entropy - ((size_0/orig_size)*entropy_0 + (size_1/orig_size)*entropy_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes one variable, finds 10 threshold values and calculates which threshold value produces the largest information gain for the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_info_gain_per_variable(column, data):\n",
    "    current_entropy = scipy.stats.entropy(data.Class.value_counts())\n",
    "    value_range = data[column].max() - data[column].min()\n",
    "    step = value_range/10\n",
    "    max_info_gain = 0\n",
    "    max_info_gain_threshold = 0\n",
    "    for i in range(1,10):\n",
    "        threshold = data[column].min() + i*step\n",
    "        split_column(column, threshold, data)\n",
    "        info_gain = information_gain(current_entropy, data)\n",
    "        if(info_gain > max_info_gain):\n",
    "            max_info_gain = info_gain\n",
    "            max_info_gain_threshold = threshold\n",
    "    return (max_info_gain, max_info_gain_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loops over all variables, finding the maximum information gain at any point in the decision tree. If the maximum information gain is below some minimum value, the function returns 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_info_gain_overall(data, entropy, used_columns, min_value = 0.005, vis = False):\n",
    "    max_info_gain = 0\n",
    "    max_info_gain_column = ''\n",
    "    max_info_gain_threshold = 0\n",
    "    \n",
    "    columns = [c for c in data.columns[:8] if c not in used_columns]\n",
    "    for column in columns:\n",
    "        result = max_info_gain_per_variable(column, data)\n",
    "        if (result[0] > max_info_gain):\n",
    "            max_info_gain = result[0]\n",
    "            max_info_gain_column = column\n",
    "            max_info_gain_threshold = result[1]\n",
    "    if(max_info_gain < min_value):\n",
    "        return 0\n",
    "    max_info_node = DecisionNode(max_info_gain_column, max_info_gain_threshold, max_info_gain)\n",
    "    if vis:\n",
    "        plt.scatter(data[max_info_gain_column], data.Class)\n",
    "        plt.axvline(x=max_info_gain_threshold)\n",
    "        plt.show()\n",
    "    return max_info_node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build_subtree is a recursive function which builds the decision tree in pre-order.\n",
    "build_ID3_tree provides the root node and makes use of build_subtree to create the rest of the tree structure.\n",
    "build_subtree also prints a visual representation of the tree structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_subtree(root, data, level, used_columns):\n",
    "    \n",
    "    # left node, or false node\n",
    "    filt = data[root.column] < root.threshold\n",
    "    data_subset = data.loc[filt].copy(deep=True)\n",
    "    entropy = scipy.stats.entropy(data_subset.Class.value_counts())\n",
    "    left_child = max_info_gain_overall(data_subset, entropy, used_columns)    \n",
    "    if(left_child == 0):\n",
    "        root.addLeftChild(PredictionNode(data_subset.Class.mode()[0]))\n",
    "    else:\n",
    "        root.addLeftChild(left_child) \n",
    "        level += 1\n",
    "        used_columns.append(left_child.column)\n",
    "        build_subtree(left_child, data_subset, level, used_columns)\n",
    "        level -= 1\n",
    "        used_columns.pop()\n",
    "        \n",
    "    # right node, or true node\n",
    "    filt = data[root.column] > root.threshold\n",
    "    data_subset = data.loc[filt].copy(deep=True)\n",
    "    entropy = scipy.stats.entropy(data_subset.Class.value_counts())\n",
    "    right_child = max_info_gain_overall(data_subset, entropy, used_columns)\n",
    "    if(right_child == 0):\n",
    "        root.addRightChild(PredictionNode(data_subset.Class.mode()[0]))\n",
    "    else:\n",
    "        root.addRightChild(right_child)\n",
    "        level += 1\n",
    "        used_columns.append(right_child.column)\n",
    "        build_subtree(right_child, data_subset, level, used_columns)\n",
    "        \n",
    "# this function checks for redundant subtrees i.e. subtrees where every prediction node has the same value\n",
    "# this function is used by build_ID3_tree to prune the redundant subtrees\n",
    "def check_subtree(node, values):\n",
    "    if(type(node) == PredictionNode):\n",
    "        values.append(node.value)\n",
    "    else:\n",
    "        check_subtree(node.left_child, values)\n",
    "        check_subtree(node.right_child, values)\n",
    "    return values\n",
    "\n",
    "def build_ID3_tree(data):\n",
    "    entropy = scipy.stats.entropy(data.Class.value_counts())\n",
    "    used_columns = []\n",
    "    root_node = max_info_gain_overall(data, entropy, used_columns)\n",
    "    used_columns.append(root_node.column)\n",
    "    build_subtree(root_node, data, 0, used_columns)\n",
    "    \n",
    "    node_stack = []\n",
    "    node_stack.append(root_node)\n",
    "    node = root_node\n",
    "    nodes_to_prune = {}\n",
    "    \n",
    "    \n",
    "    while(len(node_stack) > 0):\n",
    "        if(type(node) != PredictionNode):\n",
    "            values = []\n",
    "            values = check_subtree(node, values)\n",
    "            if(len(set(values)) == 1):\n",
    "                nodes_to_prune[node] = set(values).pop()\n",
    "                node = node_stack.pop()\n",
    "            else:\n",
    "                node_stack.append(node.right_child)\n",
    "                node = node.left_child\n",
    "                node_stack.append(node)    \n",
    "        else:\n",
    "            node = node_stack.pop()        \n",
    "        \n",
    "    node_stack = []\n",
    "    node_stack.append(root_node)\n",
    "    node = root_node\n",
    "    while(len(node_stack) > 0):\n",
    "        if(type(node) != PredictionNode):\n",
    "            if(node.right_child in nodes_to_prune):\n",
    "                node.addRightChild(PredictionNode(nodes_to_prune.get(node.right_child)))\n",
    "            else:\n",
    "                node_stack.append(node.right_child)\n",
    "            if(node.left_child in nodes_to_prune):\n",
    "                node.addLeftChild(PredictionNode(nodes_to_prune.get(node.left_child)))\n",
    "            else:\n",
    "                node_stack.append(node.left_child)\n",
    "            node = node_stack.pop()\n",
    "        else:\n",
    "            node = node_stack.pop()\n",
    "    \n",
    "    return root_node\n",
    "        \n",
    "ID3_tree = build_ID3_tree(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " IF  Excess kurtosis of the integrated profile  <  1.1076487870999996\n",
      "\t THEN  0\n",
      " ELSE  Excess kurtosis of the integrated profile  >  1.1076487870999996\n",
      "\t IF  Skewness of the DM-SNR curve  <  100.04292962330001\n",
      "\t\t THEN  1\n",
      "\t ELSE  Skewness of the DM-SNR curve  >  100.04292962330001\n",
      "\t\t IF  Mean of the DM-SNR curve  <  2.5133779262000004\n",
      "\t\t\t THEN  0\n",
      "\t\t ELSE  Mean of the DM-SNR curve  >  2.5133779262000004\n",
      "\t\t\t THEN  1\n"
     ]
    }
   ],
   "source": [
    "def visualise_tree(node, level):\n",
    "    if(type(node.left_child) == PredictionNode):\n",
    "        print(level*\"\\t\", \"IF \", node.column, \" < \", node.threshold)\n",
    "        print((level+1)*\"\\t\", \"THEN \", node.left_child.value)\n",
    "    else:\n",
    "        print(level*\"\\t\", \"IF \", node.column, \" < \", node.threshold)\n",
    "        level += 1\n",
    "        visualise_tree(node.left_child, level)\n",
    "        level -= 1\n",
    "        \n",
    "    if(type(node.right_child) == PredictionNode):\n",
    "        print(level*\"\\t\", \"ELSE \", node.column, \" > \", node.threshold)\n",
    "        print((level+1)*\"\\t\", \"THEN \", node.right_child.value)\n",
    "    else:\n",
    "        print(level*\"\\t\", \"ELSE \", node.column, \" > \", node.threshold)\n",
    "        level += 1\n",
    "        visualise_tree(node.right_child, level)\n",
    "        \n",
    "visualise_tree(ID3_tree, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(node, data_input):\n",
    "    while(type(node) != PredictionNode):\n",
    "        if data_input[node.column] > node.threshold:\n",
    "            node = node.right_child\n",
    "        else:\n",
    "            node = node.left_child\n",
    "    return node.prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the accuracy of the ID3_tree on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy:  0.9743016759776536\n"
     ]
    }
   ],
   "source": [
    "real_values = [val for val in test_data.Class]\n",
    "pred_values = []\n",
    "for i in test_labels:\n",
    "    pred = make_prediction(ID3_tree, test_data.loc[i])\n",
    "    pred_values.append(pred)\n",
    "correct = len([1 for r,p in zip(real_values, pred_values) if (r==p)]) / float(len(pred_values))\n",
    "print(\"Test set accuracy: \", correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set F1 score:  0.8516129032258065\n"
     ]
    }
   ],
   "source": [
    "f1_score = sklearn.metrics.f1_score(real_values, pred_values)\n",
    "print(\"Test set F1 score: \", f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
