{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree is built from scratch, however I use some helper functions from other libraries: pandas for reading the data into a dataframe, random for shuffling the data before splitting, scipy.stats for the entropy function, and sklearn.metrics for the F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import scipy.stats\n",
    "import sklearn.metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\n",
    "    \"Mean of the integrated profile.\",\n",
    "    \"Standard deviation of the integrated profile.\",\n",
    "    \"Excess kurtosis of the integrated profile.\",\n",
    "    \"Skewness of the integrated profile.\",\n",
    "    \"Mean of the DM-SNR curve.\",\n",
    "    \"Standard deviation of the DM-SNR curve.\",\n",
    "    \"Excess kurtosis of the DM-SNR curve.\",\n",
    "    \"Skewness of the DM-SNR curve.\",\n",
    "    \"Class\"\n",
    "]\n",
    "original_data = pd.read_csv('HTRU_2.csv', names = column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I split the data into the pulsars (data_1) and not pulsars (data_0). I then shuffle these individually, and take the first 90% of the shuffled data_0 and data_1, and use this for training data. The remaining 10% is for testing data. I split them individually so I have an equal proportion of positive samples in the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(range(original_data.shape[0]))\n",
    "\n",
    "data_0 = original_data.Class == 0\n",
    "labels_0 = [i for i in data_0.index if data_0[i]]\n",
    "data_1 = original_data.Class == 1\n",
    "labels_1 = [i for i in data_1.index if data_1[i]]\n",
    "\n",
    "random.seed(503)\n",
    "random.shuffle(labels_0)\n",
    "random.shuffle(labels_1)\n",
    "\n",
    "split_point_0 = int(0.9*len(labels_0))\n",
    "split_point_1 = int(0.9*len(labels_1))\n",
    "\n",
    "train_labels = labels_0[:split_point_0] + labels_1[:split_point_1]\n",
    "test_labels = labels_0[split_point_0:] + labels_1[split_point_1:]\n",
    "\n",
    "random.shuffle(train_labels)\n",
    "random.shuffle(test_labels)\n",
    "\n",
    "train_data = original_data.loc[train_labels].copy(deep=True)\n",
    "test_data = original_data.loc[test_labels].copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split_column() creates a temporary column 'temp' based on the value of the provided column. If the value in the provided column is above the threshold value, the 'temp' value is 1, otherwise 0. This function is used in information_gain(), to calculate the information gain obtained from a particular variable split with a particular threshold value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_column(column_name, threshold, data):\n",
    "    data['temp'] = 0\n",
    "    filt = data[column_name] > threshold\n",
    "    data.loc[filt,'temp'] = 1\n",
    "    \n",
    "def information_gain(entropy, data):\n",
    "    if(data.shape[0] < 0.01*original_data.shape[0]):\n",
    "        return 0\n",
    "    filt = data['temp'] == 0\n",
    "    counts = data.loc[filt, 'Class'].value_counts()\n",
    "    entropy_0 = scipy.stats.entropy(counts)\n",
    "    size_0 = data[filt].shape[0]\n",
    "    filt = data['temp'] == 1\n",
    "    counts = data.loc[filt, 'Class'].value_counts()\n",
    "    entropy_1 = scipy.stats.entropy(counts)\n",
    "    size_1 = data[filt].shape[0]\n",
    "    orig_size = data.shape[0]\n",
    "    return entropy - ((size_0/orig_size)*entropy_0 + (size_1/orig_size)*entropy_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes one variable, finds 10 threshold values and calculates which threshold value produces the largest information gain for the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_info_gain_per_variable(column, data):\n",
    "    current_entropy = scipy.stats.entropy(data.Class.value_counts())\n",
    "    value_range = data[column].max() - data[column].min()\n",
    "    step = value_range/10\n",
    "    max_info_gain = 0\n",
    "    max_info_gain_threshold = 0\n",
    "    for i in range(1,10):\n",
    "        threshold = data[column].min() + i*step\n",
    "        split_column(column, threshold, data)\n",
    "        info_gain = information_gain(current_entropy, data)\n",
    "        if(info_gain > max_info_gain):\n",
    "            max_info_gain = info_gain\n",
    "            max_info_gain_threshold = threshold\n",
    "    return (max_info_gain, max_info_gain_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loops over all variables, finding the maximum information gain at any point in the decision tree. If the maximum information gain is below some minimum value, the function returns 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_info_gain_overall(data, entropy, min_value = 0.005, vis = False):\n",
    "    max_info_gain = 0\n",
    "    max_info_gain_column = ''\n",
    "    max_info_gain_threshold = 0\n",
    "    for column in data.columns[:8]:\n",
    "        result = max_info_gain_per_variable(column, data)\n",
    "        if (result[0] > max_info_gain):\n",
    "            max_info_gain = result[0]\n",
    "            max_info_gain_column = column\n",
    "            max_info_gain_threshold = result[1]\n",
    "    if(max_info_gain < min_value):\n",
    "        return 0\n",
    "    max_info_node = Node(max_info_gain_column, max_info_gain_threshold, max_info_gain)\n",
    "    if vis:\n",
    "        plt.scatter(data[max_info_gain_column], data.Class)\n",
    "        plt.axvline(x=max_info_gain_threshold)\n",
    "    plt.show()\n",
    "    return max_info_node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class Node represents any node in the decision tree which has children\n",
    "PredictionNode represents a node with no children i.e. it is a leaf node\n",
    "DecisionTree represents a collection of nodes, beginning with the root node. This class keeps track of how many nodes are in the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, column, threshold, info_gain):\n",
    "        self.column = column\n",
    "        self.threshold = threshold\n",
    "        self.info_gain = info_gain\n",
    "    def addLeftChild(self, child):\n",
    "        self.left_child = child\n",
    "    def addRightChild(self, child):\n",
    "        self.right_child = child\n",
    "    def print_node(self):\n",
    "        print(\"Column: \", self.column)\n",
    "        print(\"Threshold: \", self.threshold)\n",
    "        print(\"Info gain: \", self.info_gain)\n",
    "        \n",
    "class PredictionNode:\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "    def prediction(self):\n",
    "        return self.value\n",
    "    def print_node(self):\n",
    "        print(\"Prediction: \", self.prediction)\n",
    "        \n",
    "class DecisionTree:\n",
    "    def __init__(self, root_node):\n",
    "        self.root_node = root_node\n",
    "        self.count = 1\n",
    "    def addNode(self):\n",
    "        self.count += 1\n",
    "    def countNodes(self):\n",
    "        return count        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build_subtree is a recursive function which builds the decision tree in pre-order.\n",
    "build_ID3_tree provides the root node and makes use of build_subtree to create the rest of the tree structure.\n",
    "build_subtree also prints a visual representation of the tree structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " IF  Excess kurtosis of the integrated profile.  <  1.1076487870999996\n",
      "\t IF  Excess kurtosis of the integrated profile.  <  0.5105479293999999\n",
      "\t\t THEN  0\n",
      "\t ELSE  Excess kurtosis of the integrated profile.  >  0.5105479293999999\n",
      "\t\t IF  Standard deviation of the DM-SNR curve.  <  27.827414752\n",
      "\t\t\t THEN  0\n",
      "\t\t ELSE  Standard deviation of the DM-SNR curve.  >  27.827414752\n",
      "\t\t\t IF  Standard deviation of the integrated profile.  <  41.827887837999995\n",
      "\t\t\t\t THEN  0\n",
      "\t\t\t ELSE  Standard deviation of the integrated profile.  >  41.827887837999995\n",
      "\t\t\t\t IF  Excess kurtosis of the integrated profile.  <  0.7474258104\n",
      "\t\t\t\t\t THEN  0\n",
      "\t\t\t\t ELSE  Excess kurtosis of the integrated profile.  >  0.7474258104\n",
      "\t\t\t\t\t THEN  1\n",
      " ELSE  Excess kurtosis of the integrated profile.  >  1.1076487870999996\n",
      "\t IF  Excess kurtosis of the integrated profile.  <  2.5004606028\n",
      "\t\t IF  Excess kurtosis of the integrated profile.  <  1.5249815067\n",
      "\t\t\t IF  Standard deviation of the DM-SNR curve.  <  17.5339579053\n",
      "\t\t\t\t THEN  0\n",
      "\t\t\t ELSE  Standard deviation of the DM-SNR curve.  >  17.5339579053\n",
      "\t\t\t\t IF  Mean of the integrated profile.  <  76.29375\n",
      "\t\t\t\t\t THEN  0\n",
      "\t\t\t\t ELSE  Mean of the integrated profile.  >  76.29375\n",
      "\t\t\t\t\t THEN  1\n",
      "\t\t ELSE  Excess kurtosis of the integrated profile.  >  1.5249815067\n",
      "\t\t\t IF  Mean of the DM-SNR curve.  <  55.96956522180001\n",
      "\t\t\t\t IF  Standard deviation of the integrated profile.  <  62.994890445\n",
      "\t\t\t\t\t IF  Mean of the integrated profile.  <  67.075\n",
      "\t\t\t\t\t\t THEN  1\n",
      "\t\t\t\t\t ELSE  Mean of the integrated profile.  >  67.075\n",
      "\t\t\t\t\t\t THEN  1\n",
      "\t\t\t\t ELSE  Standard deviation of the integrated profile.  >  62.994890445\n",
      "\t\t\t\t\t THEN  0\n",
      "\t\t\t ELSE  Mean of the DM-SNR curve.  >  55.96956522180001\n",
      "\t\t\t\t THEN  1\n",
      "\t ELSE  Excess kurtosis of the integrated profile.  >  2.5004606028\n",
      "\t\t THEN  1\n"
     ]
    }
   ],
   "source": [
    "def build_subtree(root, data, tree, level):\n",
    "    \n",
    "    # left node, or false node\n",
    "    filt = data[root.column] < root.threshold\n",
    "    data_subset = data.loc[filt].copy(deep=True)\n",
    "    entropy = scipy.stats.entropy(data_subset.Class.value_counts())\n",
    "    left_child = max_info_gain_overall(data_subset, entropy)\n",
    "    tree.addNode()\n",
    "    if(left_child == 0):\n",
    "        root.addLeftChild(PredictionNode(data_subset.Class.mode()[0]))\n",
    "        print(level*\"\\t\", \"IF \", root.column, \" < \", root.threshold)\n",
    "        print((level+1)*\"\\t\", \"THEN \", data_subset.Class.mode()[0])\n",
    "    else:\n",
    "        root.addLeftChild(left_child)  \n",
    "        print(level*\"\\t\", \"IF \", root.column, \" < \", root.threshold)\n",
    "        level += 1\n",
    "        build_subtree(left_child, data_subset, tree, level)\n",
    "        level -= 1\n",
    "        \n",
    "    # right node, or true node\n",
    "    filt = data[root.column] > root.threshold\n",
    "    data_subset = data.loc[filt].copy(deep=True)\n",
    "    entropy = scipy.stats.entropy(data_subset.Class.value_counts())\n",
    "    right_child = max_info_gain_overall(data_subset, entropy)\n",
    "    tree.addNode()\n",
    "    if(right_child == 0):\n",
    "        root.addRightChild(PredictionNode(data_subset.Class.mode()[0]))\n",
    "        print(level*\"\\t\", \"ELSE \", root.column, \" > \", root.threshold)\n",
    "        print((level+1)*\"\\t\", \"THEN \", data_subset.Class.mode()[0])\n",
    "    else:\n",
    "        root.addRightChild(right_child)\n",
    "        print(level*\"\\t\", \"ELSE \", root.column, \" > \", root.threshold)\n",
    "        level += 1\n",
    "        build_subtree(right_child, data_subset, tree, level)\n",
    "\n",
    "def build_ID3_tree(data):\n",
    "    entropy = scipy.stats.entropy(data.Class.value_counts())\n",
    "    root_node = max_info_gain_overall(data, entropy)\n",
    "    decision_tree = DecisionTree(root_node)\n",
    "    build_subtree(root_node, data, decision_tree, 0)\n",
    "    \n",
    "    return decision_tree\n",
    "        \n",
    "ID3_tree = build_ID3_tree(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(decision_tree, data_input):\n",
    "    node = decision_tree.root_node\n",
    "    while(type(node) != PredictionNode):\n",
    "        if data_input[node.column] > node.threshold:\n",
    "            node = node.right_child\n",
    "        else:\n",
    "            node = node.left_child\n",
    "    return node.prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the accuracy of the ID3_tree on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy:  0.9793296089385475\n"
     ]
    }
   ],
   "source": [
    "real_values = [val for val in test_data.Class]\n",
    "pred_values = []\n",
    "for i in test_labels:\n",
    "    pred = make_prediction(ID3_tree, test_data.loc[i])\n",
    "    pred_values.append(pred)\n",
    "correct = len([1 for r,p in zip(real_values, pred_values) if (r==p)]) / float(len(pred_values))\n",
    "print(\"Test set accuracy: \", correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set F1 score:  0.8840125391849529\n"
     ]
    }
   ],
   "source": [
    "f1_score = sklearn.metrics.f1_score(real_values, pred_values)\n",
    "print(\"Test set F1 score: \", f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
